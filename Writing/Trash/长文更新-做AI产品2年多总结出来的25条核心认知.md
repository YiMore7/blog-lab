
# 长文更新 | 做AI产品2年多总结出来的25条核心认知

原创 Kenny肯尼

[↓↓↓](javascript:)  
  
Kenny 肯尼  
  
[↑↑↑](javascript:)

_2025年10月9日 20:27_ _上海_

全文19,473字，阅读约50分钟，原文发于2月

近期gap有空，结合近半年突飞猛进的模型侧和应用层发展，以及自己做Agent的实践，对之前的《25条认知》做了修订，主要在第三部分「如何设计产品」，核心观点如下：

*   找到Model-Product-Market-Fit最关键，模型能力（现状&未来）匹配用户需求（存量&增量）
    
*   用户需求是渐变的光谱，按过去的旧分类，AI只能替代存量解决方案，无法创造增量市场
    
*   给用户交付一个结果，而非单纯做体验，通过管理用户预期，收敛场景，最终满足和超出用户预期
    
*   产品框架要最大化拿到模型进步的红利，产品不在于弥补模型的不足，而在于充分发挥模型在目标场景的作用
    
*   把模型当做人，一个非常聪明但一张白纸的人，在教模型干活之前，先想想人是怎么做事的，然后帮助它landing
    
*   接受失控，相信模型，相信用户，相信社区，然后会见证很多超出计划和预期的美妙结果
    

# 前言

从23年初参与AI项目到现在，做过亿级用户规模的AI特效，也落地过更复杂的营销创作工具，还探索过Agent，是我最累最忙的两年多，在此期间积累了一些成功经验，更多是失败教训，但总体拿到的手感反馈的确比较多。

比较幸运所在的影像业务，**有大模型最丰富的落地场景，无论是文本、图片、视频还是音频，无论是单一模态还是多模态组合，并且可以立即拿到用户反馈，建立认知**。在大家还不清楚大模型的时候，就开始思考怎么落地；在大家还不知道怎么落地时，已经拿到很多实践反馈；在大家开始实践时，已经往更深更广更远的维度来抽象思考了。

这篇文章字数比较多，有不少共识和非共识的内容，也有很多具体的信息和细节。**没必要试图记住这些原则，而是感受它，看哪些是有共鸣的**，哪些是没经历过但后续要刻意关注的。里面也有不一定对，或者只在特定条件下成立，边看边甄别。

# 如何迭代认知

### 1\. 理解大模型，需要理论和实践。你不上手，就很难真正的理解，也无法做出有价值的判断

**需要建立认知框架，才能避免迷失在信息的乱流中**，否则每天一睁眼，那么多AI信息，又多又快，让人焦虑。大模型原理掌握Transformer、Diffusion、DiT、SFT、RL等，这类课程其实网上非常多了，这里推荐OpenAI创始人之一Andrej Karpathy的Deep Dive into LLMs like ChatGPT（目前最好的LLM入门），还有张涛老师的[Stable Diffusion 原理](https://mp.weixin.qq.com/s?__biz=MzAxNDMxMzQyNg==&mid=2650003177&idx=1&sn=716543a52c4f30ccf6cebf3b85c26088&scene=21#wechat_redirect)，[Deepseek R1技术解读](https://mp.weixin.qq.com/s?__biz=MzAxNDMxMzQyNg==&mid=2650003381&idx=1&sn=f387c93ecd92fbcc8207b656b4b4b02a&scene=21#wechat_redirect)，MIT的How to AI (Almost) Anything，建议先看科普视频，再看论文和文档，不然会很吃力，尤其是像我这样的文科生

**理解原理的基础上，还要实际上手体验**，否则就像你高中，上课听了都会，下课做题傻眼。那些自媒体说的颠覆性能力，算法跟你说咱们模型的各项评分多少，你是没有概念的。可能看似很高的分数，其实给用户使用依然是灾难。或者咱们的能力超过竞品模型，但在实际体验，用户感受不到这个差距。最简单的方式，就是去即梦、可灵、豆包等简单易上手的工具来体验模型效果，以及在工作中尽量使用AI提效。

**体验之后，最好有项目可以实践，在更大场景验证。**你自己体验，跟做出产品给更多用户使用，依然有巨大的认知鸿沟。因为业务和岗位原因，你可能没有研发资源，那怎么办？先利用外部工具跑起来，验证收益再投入资源。AI项目有高度不确定性，与其等老板给你资源立项，不如自己先思考起来，小步快跑去尝试，帮助个人提效和业务内部提效。

**在项目实践中，不要当无脑的螺丝钉，成为分工细化的受害者**。在大厂分工很细，有用户产品、框架产品、作者产品、策略产品、工具产品，一个项目经常要多个产品和不同方向的研发、算法来完成，分工的好处是可以把每件事做得很精细极致，适合规模化阶段。但是做AI产品，分工太细，不一定是好事，比如一个产品不管数据、策略、供给，只做前端交互用户体验，那可能做10个AI项目，都不是真的AI产品，或者一个算法产品只做标准、打标、清洗，而不管终端的用户场景，可能也是打标poc。要全链路都了解，从而形成你的判断力。

现在的组织分工，岗位边界，都是服务移动互联网的产品形态，但其实并不匹配新一代的AI产品，如果还是固守自己过去的边界，不学习，不承担边界之外的任务，那么是很难在AI时代迅速成长的。

### 2\. AI项目0-1阶段协作很痛苦，需要团队对模型理解有共识，建议组成AI native的闭环小团队

如果你做的AI项目，在业界已经是成熟模式，比如AI特效，需要更多人分工做大规模。但人一多，每个人对Diffusion、DiT的效果理解不一样，会经历比较混乱的阶段，甚至各方会互相指责。这种情况下，就需要项目组内各位同学短期内多看、多体验，努力补课，**团队成员在模型理解上达成共识**，知道哪些是切入点，哪些优化空间不大。

**偏探索性的AI项目，比如Agent，最好小团队闭环，减少沟通成本**，组织的摩擦和繁重的会议，对精力的损耗超级大。想想你们一周那么累，但真正投入到有价值的事情的占比有多少？可能超过20%就算不错了。

**人经常会高估个人的能力，低估组织的力量**。deepseek的人才不一定是最顶尖的，也就一百多人，但当团队有共识，把精力都在投入到真正做事上，可能实际的产出会很大，短期更容易跑出来。

关于AI native的组织，推荐看lovable的两位员工写的 《The New Designer Playbook》和《How to thrive in the Al era；The rise of the AI-native employee》；42章经的《组织能力才是AI公司真正的壁垒》；Calvin的《Reflections on OpenAI》，Lenny的《25 proven tactics to accelerate AI adoption at your company》。结合自己在公司内封闭AI项目的的实践，总结如下：

*   每个人都是多面手，而不是分工细化的螺丝钉
    
*   在AI native的项目里，需要新的分工和新的技能，每个同学都要开始**做自己不擅长的新东西，然后发现自己不行，所以更愿意利用AI**。如果做的事情已经很熟了，哪怕麻烦点，大家依然会倾向于用人工的方式解决。
    
*   行动比流程更关键，快速干，干中学，不要那么多拉通对齐
    
*   行动足够快，那么失败成本就足够低
    

![图片](assets/1763990379-37d80127b73f829661c0d17b431e0b18.svg)

### 3\. 对过去成功路径的过度依赖，可能是未来成功的阻碍

很多年轻同学入职即大厂，一直在成熟产品上做ab优化，最擅长的就是分析数据拆漏斗，找到流失最大的环节，然后针对性优化，不清楚哪个手段更有效，再多分几个实验组，最后ab涨0.2%，开开心心推全实验。**但如果把这套ab经验套在做0-1项目，可能会让你在错误的或不重要的方向上浪费时间**。比如某个项目刚上线，使用导出率很低，有同学就担心怎么办，想优化漏斗。但我对生成的效果很有信心，所以判断不应该投入太多做雕花，更重要的是找到目标用户，透传产品价值，后面转化率自然就翻了几倍。

我意识到同学们还在用精细化AB的思维来做AI创新产品，没有勇气下判断，于是在团队内分享过去的0-1经验。比如疫情做腾讯课堂极速版，48小时上线，没有什么增长策略，2周DAU千万，1年用户破亿。当时公司有很多个教育业务做，为什么我们能成为最大的公立校网课平台？因为过去大家认为，公立校的决策者是校领导，所以产品架构要以学校为单位，但我们正月里开始接待教育局领导，发现老师数字化程度太低，学校的组织架构和课程表太复杂，果断采用一个老师手机号注册->一键开课->分享链接给学生，同期另一个相似形态的是腾讯会议，也起飞了。

还有某些高阶同学，做10-100阶段太久，方法论又复杂又酷炫，已经忘记当年0-1阶段的粗糙了，会形成一种幻觉，因为我很牛逼，所以当初能做成。很起飞很爆炸的项目，大概率不是因为方案本身做的多么精细，而是抓住了关键点和机遇。**在0-1阶段，如果方案要非常精细完美面面俱到才能做成，那么这事儿可能就不成立**，我工作这几年，数据好到远超预期的方案，都是很粗糙很赶做出来的，但都把握了最关键的点。

**高阶PM做AI项目，尤其要警惕，你要避免过去具体的经验对你的干扰**，觉得自己之前在抖音是这样做的，做成了，所以现在按同样的方法在新业务也能做成，但忽略了条件和时间点的变化。我转到新业务后，一方面是输出过去的经验，另一方面，会甄别哪些是有效的，哪些是无效的，如何做本地化，避免活成自己过去讨厌的样子。

**移动互联网的数据飞轮、网络效应是构建业务壁垒的底层逻辑，但这个方法论在大模型还没被大范围验证。**Chatbot在24年都在搞投放，先圈用户，用户的行为和prompt构建数据飞轮，但实际上我们看到，用户被推荐引擎驯化的，表达能力已经非常糟糕了，用户的prompt非常的初级，低质，甚至糟糕，而模型训练需要优质的数据，所以价值不大。反倒没啥用户规模的deepseek，做出R1，然后一鸣惊人，0投放，成为史上增长最快的AI产品。

### 4\. 在不确定性的快速变化的领域，数据可能没那么重要，判断和信仰更重要

22年刚来字节，震惊于字节ab数据的先进性，觉得是产品经理的工业革命，但到后面越来越觉得，随着公司规模扩大，一些产品经理被数据和实验给异化了，逐渐丢失了深度思考的能力，没有从数据中，增加对用户的理解，挖掘新的机会点。

23年我们内部开玩笑说，后面大模型把我们产品的各种文档拿来训练，可能就可以把产品经理都裁掉了，而且数据分析AI做的比我们产品还精细全面。

**过于迷恋数据，会导致我们陷入局部最优解，而局部最优解不一定是全局最优解**，因为我们的信息和视野有限，拆解出来的路径可能不是最有效的路径。但人性都是短视的，就像AlphaGo，为什么能走出人类从来没有见过的神之一手，因为它看得更远，某一步貌似看臭棋，但是很多步之后，体现出它这步的精妙

我时刻提醒自己和身边的同学，**脱离数据，自己能不能独立做判断，数据是辅助，而非出发点**。其他公司都没有字节这样好的数据基建，那跳槽后，是不是都不知道该怎么做决策。很好玩的是，新同学landing到我们业务，需要参考优秀的需求单，一份是基于数据严谨推导的，另一份是我写的没有数据推导的需求单，但当时评审会上大家兴奋的让我赶紧做。

**数据会骗人，通过充分信息和严谨的逻辑可以绕开数据的陷阱。**不止一次，别人把数据扔在我脸上，我发现当跟我的逻辑推断不一样，我会有信心的让对方再算一遍，注意口径有没有问题。无论PM还是DA，都有可能犯数据错误，因为并行的事情太多，有时候就机械性地跑数据，而没有真正思考用户的场景。

判断和信仰有多重要，可以看最近阿里吴妈在云栖大会上的《通往ASI之路》，一场演讲就让阿里市值涨了3000亿港币，这次打动市场的不是闪购的订单量，而是阿里对AI的信仰和判断。

### **5\. 细节很重要，不要依赖别人抽象过的总结性汇报做产品判断**

在大厂各类专题汇报和周报很重要，是庞大组织能运行的机制保障，但汇报总结有效的前提是，我们充分共享了context，面对文档上的一句话，大家都能理解背后更丰富的信息，比如听到「扩供给」，都能大概想到有哪些策略，服务的目标是什么。

但是面对新事物，如果还是依赖总结性的汇报，那很可能会做出错误的判断，比如说这个模型能力分数达到4.5分，行业第一，然后我们做个某某feature，就可以颠覆业界。或者说，用户的某某需求，目前人工操作很复杂，链条长，可以通过大模型agent来解决，替代人工。但实际上，一上手，可能都不大行。**在正确的时间做正确的决策，依赖对细节的充分理解感受。**多看case，多调研用户，多上手体验产品，这是最朴素但最有效的方法。

用ChatGPT、Claude、Gemini、DeepSeek、豆包、Kimi、Midjourney、即梦、可灵等，看不同模型在同个任务上的表现差异，不同模型各自擅长和不擅长的任务，每次模型的大版本更新，就去简单测一测，也看看社媒上其他用户的case。

### **6\. 未来更多是演化出来， 而不一定是计划出来**

人获取的信息和认知有限，所以经常驾驭不了一个很宏大很长周期的东西。但人又是没有安全感的生物，所以经常会在回忆中，美化和合理化自己的规划能力。这种甜蜜回忆越多，对不确定性的未来的掌控欲就越大。**执着于过于复杂的计划和可预测的目标，反倒压制了真正的创新，错过了真正的机会。**

比如我们的不少晋级答辩文档，会写基于业务目标，我如何拆解，然后如何按计划实现，最终拿到结果。但我们其实都心知肚明，做事情的过程可能很多都是混乱，不断调整的，我们是最后关头才把过去的事情都点线面串起来，进行简化，然后让评委更好的理解。答辩这样很合理，但不要把答辩思维生搬硬套到日常的做事，除非你做的事情很成熟。

这个世界充满了运气和变量，比如英伟达芯片最开始是为了让打游戏更快，后面没想到GPU很适合神经网络这类超大并行矩阵计算；辛顿他们设计出神经网络，但因为没有足够的算力，没啥效果，被视为异端而只能在加拿大默默研究；李飞飞最开始做ImageNet，花了不少钱，但这么大的数据集也没啥用。但当他们三者遇到一起，就开启了AI的关键时刻。不是某一个智者洞悉一切，安排上述三人按项目推进的。

今年以来VC也都有了思路转变，之前在移动互联网看项目，会算这个项目的业务壁垒、商业模式，看清楚了再投；但大模型其实很长时间都没有跑通商业模式，哪怕OpenAI，所以过去VC出钱很谨慎。现在VC投钱更看重，创始人是否靠谱，是否有发自内心的长期愿景，而具体的实现路径反倒没那么重要。

### **7\. 保持学习，保持交流，准备好自己迎接更大的机会**

22年底到23年，都在卷Chatbot，到25年，基本战局已定，基本没有新玩家的机会；24年因为Cursor，大家开始做不同行业的IDE；再到25年，因为Manus，纷纷都做通用Agent和不同行业的垂类Agent。目前AI已经渗透到工作和生活的方方面面，但大部分AI产品都还是早期阶段，还不足以颠覆移动互联网。业界常说的，移动互联网早期做手电筒，然后手机应用商店，最后发现抖音、微信、美团、拼多多才是移动互联网的真正大机会。

当前我们可能在做手电筒，或应用商店（GPTs目前也没有跑通），应该还没有出现抖音级别的机会。但我们需要拿项目练手，总结，交流，学习，因为抖音不是第一天做移动互联网的人做出来的。张一鸣在九九房里做推荐引擎，但意识到这是小机会，然后把推荐引擎放在内涵段子、头条，直到在抖音，跟上下滑的短视频交互结合，一举反超腾讯。

那么AI时代的抖音、微信、美团、淘宝可能都还没出来，大模型作为一个技术要素，会引发什么奇妙的化学反应呢？我们其实也没有真正看清楚，可能苹果和微信是生态位的终局赢家，比如微信搜索接入deepseek，可以通过智力串联起微信生态里的内容和服务。但也可能下一个抖音不是抖音的形态，我们只能先积累认知经验，识别身边的靠谱伙伴，等待更大机会的到来。

# 如何找PMF

### **8\. 找Model-Product-Market-Fit是核心能力**

需要理解模型，就像你在移动互联网早期，要理解4G、GPS、智能手机一样；不理解模型的原理，就会在一些错误的细节上白白浪费精力，比如大模型的幻觉，本质因为是next token prediction，是个概率问题，或者容易异想天开，过早做非常复杂的Agent项目。

**理解模型的边界，理解用户的需求，然后通过一套产品化解决方案来切入这个交叉点**，是AI应用产品经理的核心能力。对模型的理解，要有定量和定性。不是读了多少篇论文，其实不少论文读得飞起的人，不一定理解模型在复杂现实环境里的能力；也不是做了很多测评，因为测评也是简化的环境，我被很多打分和榜单骗过。你用多了，看多了，就有判断，模型能做什么，做到什么程度。

### **9\. AI有的是提供草稿起点，或解决最后一公里，或辅助人完成任务，或闭环完成简单任务**

即使到今天，AI在大部分任务上，都还无法取代完整的人类工作流。当你要做一个AI项目，可以思考，这个是给用户提供一个初始草稿，方便他快速二次修改，还是基于用户的草稿，做最后的润色加工。比如23年初很亮眼的Gamma，就是输入prompt，给你一个不错的PPT草稿，然后你在PPT上继续修改文字，大大提高用户的效率，同时管理了用户的预期，不是拿着PPT直接去演讲的。

还例如在nhentai这个全球某类漫画的历史排行榜，第二名Long Distance Train是作者hr555用diffusion生成的，共30页的剧情内容，作者自己画线稿，然后用AI上色，AI解决了最后一公里问题。

Granola的设计也很妙，你边听边做笔记，跟你之前的习惯一样，但AI可以把语音转录为文字，最后通过一键优化，把你的笔记和转录文稿整合为完整的笔记，有重点又完整，既解决了AI总结的没有重点，又降低了人工记笔记的多线程认知负荷，是很自然的辅助。

同样都是会议转录，Plaud采用了不同的思路，它独立完成会议转录和总结，几乎在取代一个会议助理的角色。产品逻辑也很简单，开会前，点击录音，会议结束后，把录音转为文稿，并按不同行业和会议类型模板，提供对应的总结，已经比很多助理记得都更清楚。

**你想要AI多大程度的完成任务，要依赖模型的进展、场景的复杂度、以及用户能力和预期，没有标准答案。**但我们希望AI可以独立完成越来越多、越来越复杂的任务，让人类从琐事中解放出来，去做更加具有创造性的事情。

### **10\. 好玩比有用可能更容易跑出来**

大模型的幻觉、可控性差等问题，让我们做解决方案时非常棘手。因为过去移动互联网的解决方案，都是比较确定性的，用户每完成一个操作，都会对反馈有明确的预期，如果不符合预期，就会退出。想象你在视频编辑器里，点击添加某个手写字体，结果展示的是另一个宋体，你就会觉得这是什么鬼。

但另一方面，我们可以**利用大模型善于创意、发散的特点，来给用户一些非刚需的好玩场景提供惊喜**。比如AI特效，把照片变成粘土风，虽然脸也可能歪瓜裂枣的，但丑萌可爱。比如Sora出来后，我们预期会有奥斯卡般的高品质AI影视作品，但实际上到今天，DiT视频模型最大的应用场景还是在玩抽象，变身机甲战士，羊毛卷，AI打架。

比如AI扩图，本来以为是一个实用工具，没想到变成搞笑的爆款玩法。可能吸引很多人的好玩东西，会逐渐演变出来更有价值的东西。比如短剧赛道，迪士尼请好莱坞导演做竖版短剧，失败了。结果真正跑出来的是，网文平台在抖音上投放的广告素材，从片头素材再演变为完整剧集，再超过电影行业的市场规模。比如B站最开始搞二次元和鬼畜，后面出来非常有质感的中视频；抖音最开始是跳舞小姐姐对口型，但现在也有非常有节奏感的竖版中视频。

今年3月让ChatGPT一小时增长100万的，是GPT4O的吉卜力玩法，8月底nano banana让Gemini一周增长1000w，其中主要的爆款玩法是3d手办，都是好玩不实用的东西，但普通人很喜欢。

**量变引起质变，先做出好玩好看的，有播放量，更多创作者进来，然后内容的质量和丰富性会不断起来。未来可能不是计划出来的，而是演化出来的**。我们可能并不知道未来会怎么样，也可能我们对自己设想的未来的过度执着，反倒阻碍了未来的到来。

### **11\. 用户需求是渐变的光谱，按过去的旧分类，AI只能替代存量解决方案，无法创造增量市场**

在23年6月参加美国的VidCon大会，听了全球最顶尖的内容平台、内容创作者、AI工具公司对未来内容创作的分享，对我形成系统性的AI认知超级重要，即使放在现在也没有那么过时。

当时听到一句话特别印象深刻，**AI对创作的价值：Save time（提高效率）、Improve（提高质量）、Power up（做之前做不到的事）**。我很容易理解前两点，甚至觉得AI最容易的是提高效率，但实际做了发现很难，因为AI提高效率的代价是，降低效果，于是用户不满意。所以早期不少单纯提高效率的项目，其实都不是很成功。

对Power up其实不是很理解，因为我觉得用户的需求就这些，那些做不到的事情，都是科幻小说异想天开，大模型也实现不了。但后面两年的AI应用发展，让我逐渐深入的理解了这个词。

比如AI特效，不是save time提高效率，因为用户本身没啥需求，也不是对传统美颜的improve优化，因为效果很夸张，完全不真实。AI特效是 power up，让去不起天真蓝、也请不到画师的普通用户，导入一张照片，就可以变成梵高风，或者国风写真，或者让当地樱花未开的小姐姐，可以有樱花背景写真。这里反映的用户底层需求，是变美变有趣，而不是美颜的具体需求。

比如AI音乐，在音乐性上，完全比不上版权真人音乐，但是大语言模型可以让叙事性更加个性化，可以根据每个人的故事，写一首，这是过去做不到的，也出现了「还我妈生鼻」这样的爆款。**suno 不是取代音乐人的创作，而是让音乐成为每个人的一种表达方式**，正如剪映不是让你取代剪辑师，而是让你可以低门槛进行视频化的记录和表达。

**比如AI编程不是取代程序员设计师，而是让有想法的人，也可以做出app或网页，创造了增长市场，**23年初有一些AI产品试图替代figma，一句话生成UI稿，但后面都没有成功，因为发现UI稿要求精度很高，AI生成的太粗糙，且编辑困难。Claude sonnet 3.5出来后，AI编程爆发，零代码经验的也可以通过prompt做出一个小产品，从意图->UI-代码都实现了，通过AI编程做出来的产品，可能是满足某个长尾需求，或者给自己用，就不会像传统UI稿那么精细复杂。

AI编程的应用场景继续扩大，figma是个设计UI的软件，但它今年推出了Figma make，设计师直接基于设计草稿就可以生成可交互的网页；Canva是个图片模板产品，但4月也推出 canva code，图片模板创作者不再是它的唯一供给，营销图片也不是它唯一能满足的场景；秘塔搜索支持对搜索结果，生成可视化的网页，编程这里是内容的呈现方式，而不是功能。很快也可能是模型与用户的交互方式，实时生成UI，方便我们与模型进行互动。

**提高效率，提高质量，本质上都是在过去的分类下，找更优解，那么势必会与过去可能优化了10年的方案进行比较，很多时候比不过。我们有时候要回到用户最本质的需求，从渐变的光谱中，找到你的细分需求切片，然后满足它，可能是一个新的人群，新的场景，新的需求。**  

不要试图解决痛点，因为真的大范围的痛点，可能都已经被满足了，而是先去找少数人的痒点，扩大后，再拿掉，就变成大部分人的痛点。就像外卖最开始，也只是服务大学寝室打游戏的男生，不是社会大部分人的痛点。

### **12\. 有些看似伪需求，但其实是偏情绪价值的真需求**

很多需求不是真实有用的需求，但是会让用户很舒服，比如清晰度问题，其实抖音、朋友圈都会压缩画质的，但用户在导出时，依然选择清晰度和帧率开到最大。

AI超清是非常多APP的核心功能，我最开始有点困惑，用户绝大部分的照片都是比较清晰，而且朋友圈还会压画质，为什么还这么喜欢付费用AI超清？后面了解到，用了美颜滤镜之类的，会让画质柔化变糊，用户修图时放很大看，觉得糊，然后修完后，再一键AI超清，又清晰回来，就缓解了焦虑。但实际上，朋友圈其他人看是看不出来的。

**所以不要一直按理工直男的实用主义来理解用户的需求，用户是非理性的**，不然可能会错失一些需求。

### **13\. 不同模态的生成、转化都蕴藏着模型应用层的新机会**

除了从生活的需求出发，来反推模型能力，形成解决方案。**还可以拿着锤子找钉子，从模型的能力出发去找应用场景。**下图是23年我看了很多竞品后，列出来的不同模态之间的转化，对应有什么模型能力，和产品化的机会。算是一种脑爆的思路框架。

![图片](assets/1763990379-37d80127b73f829661c0d17b431e0b18.svg)

但这个箭头不一定完整，比如最开始以为会先跑出来音频->视频，因为当时的一些demo是输入一段音乐，然后基于对音乐的理解生成视频，但实际上到现在没有跑出来。反倒视频->音频先跑出来了，从suno的拍视频生成音乐，再到抖音的拍照生成AI音乐大爆款。

比如音频转文本，一直是被忽略的赛道，但是跑出来了granola、plaud、wisper flow等口碑和数据都很不错的AI产品，因为模型的转录能力足够强，强到超出甚至很多AI业内人士的预期，可以解决很多我们的日常问题。有时候，我和朋友聊完某个议题，我会把plaud转录总结的笔记发过去，对方都会震惊于AI笔记的完整性。

### **14\. 不同内容平台之间的内容迁移和转换，会带来新的工具机会**

随着TT、Youtube Shorts、Ins Reels这类短视频平台的崛起，需要引入大量的短视频，当创作者纷纷涌入TT，但他们又不擅长做短视频，就诞生了工具化的机会，比如把Youtube的中长视频改为短视频，带来了OpusClip，比如Podsqueeze把音频播客转为短视频，比如Repurpose把Twitter帖子转为短视频。

或者流光卡片把长文转为小红书图文卡片，甚至还有一些创业项目，根据你关注的话题，去网上搜索信息，然后自动整理为小红书图文卡片发布。

这个迁移过程一直在进行，比如过去就有人把知乎的内容转到公众号、微博、小红书，因为创作者都是追逐流量的，当然这类工具其实有争议，很容易变成洗稿灰产。

当用户越来越习惯问ChatGPT、Deepseek、豆包问题，Chatbot现在成为新的流量渠道，所以目前出现了GEO，有专门的机构、公司帮助你的产品更容易被ChatGPT收录，短期可以让你的产品有更多的流量，不像SEO那么卷那么成熟，不过这是跟平台方对抗的事情，长期不一定做得大。

**总之，需要持续关注下游大平台的变化，抓住机遇比努力更重要**

### **15\. 观察用户如何与模型交互，是孕育未来新一代产品的灵感来源** 

23-24年，大模型的泛化能力和开源，让ComfyUI、Coze之类的平台，创作者通过节点来创建和封装工作流，可以满足非常多的需求。创作者的创意，经常会超出你的想象。这也是为什么Midjourney、即梦、Liblib之类的产品，一定要在端内做社区，把创作者通过工具做出来的内容，作为模板，来服务更多普通用户，甚至裂变出新的创意。

比如我们做AI特效，23年总结出的**核心产品方法论是「新技术出现->大神用新技术创作爆款作品->把大神工作流一键产品化」**，直到今天，我们依然在敏锐的观察着市场变化，我们inhouse这几个人的创意，远远比不上社区的创意。

今年随着基模能力变强，不那么依赖lora、comfyUI workflow，这需要我们更加**关注普通用户与强大模型的互动后做出哪些有意思有价值的东西**。当工具的门槛降低，更多人进来，创意供给会进一步释放，正如抖音不是养了一批专业的创作者，而是让普通用户ugc成为最大的供给。

一个简单有效的方式，就是在抖音、小红书、Twitter等内容平台上看用户案例，然后进行产品化，模板化。比如最近的jaaz和higgsfield的draw-to-video功能深受好评，这也不是他们产品的天才设计，而是早在4月份，就有用户通过GPT4O来实现涂鸦P图，接下来把这个玩法做成产品能力即可。

![图片](assets/1763990379-37d80127b73f829661c0d17b431e0b18.svg)

### **16\. 不用上来就做个大产品，先从小场景切入，收敛用户预期，最大化模型效果**

等模型智力到达AGI，可能会出现一个大产品，直接面向用户掌握信息和服务的分发，但现在，可以先踏踏实实做个小产品，解决一个具体的问题，满足一个具体的需求。大的机会，意味着形成了行业共识，那么竞争是非常激烈的，就像现在LLM领域的AI搜索、AI编程，多模态领域的AI特效。

Captions这个产品是出乎我们意料的，核心功能是识别字幕，生成动画字幕，非常简单，但很早盈利，且用户粘性高。它通过大模型，把字幕识别准确率做得非常高，几乎不用改，并且再自动添加字幕动画，更符合TT短视频的风格效果，就能获得创作者的用钱投票。

模型可以做很多事情，但很多事情也做不好。**如果你觉得一个prompt对话框就可以解决大部分需求，那么你真的还没被AI毒打过。**收敛场景，收敛需求，让模型相对稳定的交付结果，这样才有用户的留存。

# **如何设计产品**

### **17\. 给用户交付一个结果，而非单纯做工具体验，重要的是效果定义和测评**

当你设计方案时，不要陷入交互的细节，而是思考，我要给用户交付的结果是什么。用户不是来细细品味你的交互审美的，而是要结果的。从这个目标倒推，哪些是通过交互解决，哪些是通过数据解决，哪些是通过模型解决，最终包装为一个完整方案。

比如deepseek，交互很粗糙，但是它给用户交付的结果，即体现在智力上，依然爆发增长。比如AI特效，关键是用户导入照片后，生成的图片好看有趣，所以关键的其实是内容选题、特效供给，而产品更多是做供给提效、消费侧性能优化，而没有折腾太多有的没的交互和流程。

既然效果是最重要的，那么对产品经理的能力模型也提出了新的要求，即要重点做标准和测评。

*   古典产品经理，是通过调研、直觉来理解用户，做产品决策，满足用户需求。如果产品判断力不行，那就是在自嗨
    
*   字节产品经理，是用实验、数据来理解用户，做产品迭代。如果指标定错了，就越努力越错，或者没办法定出一个指标，那就不知道该怎么努力。而且很有意思，当阿里和腾讯还在辩论用户体验和数据指标如何平衡时，字节早就不需要辩论了，直接看LT和GMV，如果整体LTV有提升，就推全。
    
*   AI 产品经理，是通过定义标准、测评，尽可能全面真实地反映用户对 AI 交付的结果的感受，来做 pipeline 优化和模型精调。如果标准定错了，产品优化方向就错了，如果测评不客观，那么就带来虚假的乐观
    

**谁懂用户，谁懂行业，谁就对标准和测评有最大话语权**，这里的决策非常难。因为你没有足够的资源，做到尽善尽美，永远都会有问题，永远都没有ready，永远可以继续优化。甚至同样的一个效果，可能设计师、运营、产品都会有不同的看法，谁为结果负责，那么谁就要拍板是否要上线。上线的时间点，目标用户，产品包装，运营引导，都会对最终的结果带来影响。

### **18\. 用户的预期管理，显著影响用户对效果的满意度**

在产品宣发上，经常需要吹牛逼，搞颠覆，但当用户使用时，**需要通过引导和路径设计，管理好用户的预期，让最终交付的结果符合或者超过用户预期**。否则牛逼吹破天，来了很多用户，但都留不住。

上面看似是简单的道理，但你如果不深刻理解，可能在产品方案上就会错过一些非常关键的细节，导致用户不满意，比如我们就是把解锁草稿的按钮换了一个位置，让用户更强的意识到，这是AI生成的草稿，而非最终成片，于是使用导出率显著提升了。

如何在日常中实践这个原则，很简单，在用户使用你的功能时，问自己用户希望获得的最终结果是什么；以及用户每一步操作，问问自己他们对下一步的预期是什么。

这几天在体验Typeless语音助手，它的新手引导对用户预期管理做得非常到位，提供几个示例，让用户无脑按Fn键跟着说话，发出语音指令后，AI能准确识别并且完成任务，都是一些非常简单但繁琐的任务，但用户一下子就get能做什么，后续也会用来做类似的简单事情，而不会逼它写一篇报告。

### **19\. 对话+GUI，是新的交互范式，用户不再需要学习写prompt，而是用自然语言表达和手指戳戳**

22-23年，很多人对ChatGPT和Midjourney开创的对话式交互非常迷恋，因为很符合科幻电影里的画面。有不少AI产品，都只是一个输入框，用户写完prompt后，直接出来一个结果。我当时也参与过类似的项目，但实际落地，发现自己太天真了，一方面模型能力不行，无法基于用户的一句话交付一个满意的结果，另一方面普通用户不想打开键盘，也不知道填什么prompt，所以需要在产品设计上做好用户操作成本和最终效果的平衡。

**在23-24年对增加输入框都是非常谨慎的态度，为了降低用户写prompt的门槛上**，我们总结了一系列的有效经验：

*   **交互：**
    

*   非必要，勿填prompt，让用户多填一个字，都是对用户规模和转化率的巨大折损；
    
*   如果有prompt的效果更好，那么把写prompt做成可选填，让专业用户有选择，又不影响小白用户；
    
*   如果必须填，尽可能填用户不需要额外思考的，通过推荐词降低输入门槛，并保证对prompt的响应，避免拔高用户预期后但结果又不符预期；推荐词的来源，不一定是官方预设，而是基于海量用户的prompt做聚类、清洗、召回、排序
    

*   **信息：**可以通过算法、或信息授权来获取用户意图和context背景信息，而不一定要手动输入
    
*   **流程：**把prompt填写留在最后一步，让用户先完成简单的熟悉的操作，增加沉没成本
    

**但今年我开始更相信对话式交互了**，一方面基模变得很强，无论是多模态理解、推理、还是生成，用户用非常简单的大白话，就可以拿到很详细的问题解答，生成很高质量的图片和视频，另一方面被DeepSeek、ChatGPT的教育，已经有10亿+会与模型对话的用户基础。

对话，相比按钮和上下滑，看似门槛高，但回顾历史，PC互联网的用户门槛更高，当时核心交互是鼠标和键盘，而键盘上手很难，记得小时候练打字练了很久，尤其记住键盘字母排布，不亚于记日语五十音，而且打印店的一个重要业务是把手写稿打字为电子文档。

在项目实践里，发现模型的泛化能力，结合用户的互动，经常会超出我们的预期。于是我们**把输入框放在更明显的入口，接最大化的承接模型的红利，用户的每次对话，都是一次需求收集**，通过模型，突破我们过去无法做到的事情。

我们意识到，用户不是排斥对话，而是排斥跟一个啥都不懂的新人说话，因为要事无巨细地把所有背景信息、要求都讲清楚，这非常累。如果是跟身边的熟人，简单说一句，效率其实是最高的。而AI产品就是解决对话的context缺失问题。

行业里，大家也都在更加激进地尝试对话+GUI的交互范式：

*   **Lovart**把figma的**画布**，与右侧的对话结合起来，可以辅助构思脚本，批量生成图片，并且7月在画布上设计了一整套的评论系统 **ChatCanvas**，过去在figma上点击某个区域写评论，是给协作者看的，但lovart，是写给AI看的
    
*   **Higgsfield**的**draw-to-video**，只需上传一张静态图，在上面绘制涂鸦、文字或箭头等元素，即可按涂鸦的意思生成具有电影质感的视频画面，指哪儿打哪儿，一发布就直接爆了
    
*   **Elevenlabs**重点做TTS文字生成声音，虽然真实且有情绪，但是与人的表达依然有差距，但如果通过prompt告诉AI哪里重读、哪里停顿，还是很麻烦的，于是它推出**Actor mode**，非常巧妙的解决了这个问题，你就像一个指导老师，你来读一遍，然后放给AI听，它就知道怎么读了，真的这个交互太妙了，太强了，就是我们人类现实生活中，老师和学生之间的互动。
    
*   **ChatGPT**和**豆包**的**视频通话**，还有**共享屏幕**，也是非常简单直觉的，把你的context让AI看到，就像跟朋友通话一样，在一个同事那么看到一句话，很妙：世界即屏幕，物体即图标，注视即交互，用户即主角
    
*   **Wisper Flow**，点击电脑的**Fn键**，即可听到你的说话内容，然后转录为文字，体验起来非常爽，有点像之前的对讲机，只不过这次是跟AI讲，而不是跟人讲。
    
*   **Granola**，你只管像之前一样记笔记，AI在后台摸摸把会议录音转录成文字稿，当你开完会，一键即可把你的笔记重点和AI转录稿整合为详细又有重点的最终笔记。
    

在Twitter看到AI创作者Brett的一段话，很有感触，在此分享：The best AI artists aren’t just good at prompting—they’re good at directing. They know how to generate, filter, combine, and remix until something original emerges. 意思是，最出色的 AI 艺术家，不只是会写提示词，更擅长于‘导演’。他们懂得如何生成、筛选、融合与重组，直到独一无二的作品浮现。

**如何做AI产品的交互，可能要回到线下生活，看人和人之间，人和世界之间是如何交互的，然后为人和AI设计一套更加多维自然的交互，而不是在一个页面里排布按钮。**

### 20\. 用户不用写Prompt，但对产品研发来说，PE工程依然重要

关于调PE（Prompt Engineering）是否重要，22-24年一直很有争议，最开始都在吹Prompt工程师，到后面又说prompt已死，自媒体的风向总是令人困惑，那在业务实践中实际是怎么样呢？

首先，要区分两类prompt，一种是用户写的意图，比如用户跟ChatGPT的对话，另一种是AI产品背后的处理逻辑，比如system prompt，对用户不可见，上述的争议经常是因为混淆了两者。

**用户不需要学prompt，但AI产品的PE工程，依然非常重要，甚至更加重要**。因为今年base model进步很快，且很强，导致我们自己训的垂类模型，可能效果还不如通用模型+PE。最近比较火的 Agent 产品，其实都可以用base model+PE快速搭出来的，不需要从头自己训垂类模型，当然这里有很多工程上的苦活脏活，不是个体户几天就能搭出来的。

过去两年多，我观察且亲历PE的3个阶段：

*   最早是算法同学写Prompt，因为这个太像代码命令行了，产品觉得自己不懂
    
*   后面发现产品可以写得更好，因为prompt关键是对业务、用户、场景的理解，我23年就跟算法同学一起调PE，测效果
    
*   再后面，发现设计师、内容策划、运营、工程研发等写得更好，因为关键是行业know how，比如最近我做的一个项目，就非常依赖设计师调PE，需要很强的垂直场景的认知和判断。最近我就在小群里跟设计师说，产品经理有个吊用。
    

这里反映了3个趋势：

*   **模型的能力越来越强：**大模型就像一个很聪明但一张白纸的神童，你需要通过PE和Context输入，快速landing它，它就可以上手干活了，而不需要从0-1生一个孩子，经过九年义务教育，才能干活。
    
*   **模型应用的场景和行业越来越多**：23年的大模型应用都是很通用的简单的场景，但25年大模型进入各个垂直行业，更加纵深，意味着行业know how对大模型发挥作用更加重要
    
*   **产品的边界模糊，岗位的边界也模糊了**：都是基于base model搭pipeline，算法可以搭，产品可以搭，设计师可以搭，工程研发也可以搭，我们现在的岗位工种划分，在未来可能会发生变化
    

至于怎么写prompt，我其实也不是很专业，只能分享一些核心的learning：

*   **把模型当做一个人，而不是一个死板的机器：**相信模型的智力，很多事情你讲得太细，他反倒发挥的不好，可以通过lazy prompt的方式，先写个粗糙简单的，然后不断细化调整，而不是一上来就写一大段很复杂的。
    
    去年做 PE，大模型还是一个实习生，你要清清楚楚在 prompt 里告诉它做事 SOP，包括背景信息，先做 A，再做 B，然后对交付的结果要求细化出标准abc，今年做 PE，因为模型进步到接近正式员工，你在 PE 里告诉它怎么做，反倒限制了它的能力，不如告诉它你想要什么，它自己想各种办法去完成。
    
    而且在世界知识，美学等非标准化的 context 上，大模型逐渐跟人对齐，不需要你仔细给它很多输入了。现在要把大模型当做一个厉害的新员工，你要做的，是帮它 landing，而不是教它怎么按你的方法做事
    
*   **多与模型对话，了解不同模型的擅长和偏好：**ChatGPT、Gemini、Claude、豆包、DeepSeek，每个模型，每个版本，表现都不一样，多聊天，就会感受他们之间的差异和差距，有的模型说话很好听但干活拉胯，有的模型眼神儿贼好，有的模型很严谨靠谱
    
*   **测评集是PE优化的最佳工具：**准备好测评集，一般说来20个左右，就足够你优化PE了，比如用头3个case，都表现不错，但测到第4个，效果不行，就找到原因是什么，再去反推优化PE。
    
*   **不要太沉迷于调PE：**效果的上限是模型本身决定的，PE的空间相对有限，如果发现调不动了，要么上产品策略，要么搞数据做精调，用户需要的是交付的结果，而不是精妙的prompt。PE优化只能提高下限，底模进步才能提高上限
    

### **21\. 把AI封装为原子能力，带来乘数效应，而非单纯的漏斗转化逻辑**

乘数效应，听起来是个大词黑话，但这个概念对我们过去的实际工作是有真的指导意义，帮助我们在一些关键判断上，做出更长期有价值的决策。具体来说，你做的一个产品能力，是否用户用完即走，然后你需要费尽心思找更多入口导流，或者努力优化转化漏斗，才能维持这个产品的生命周期，还是说用户用完有资产沉淀，可以帮助他们未来更好的使用，或者服务和激发更多用户使用。

剪映Capcut的月活达到8亿MAU，在人类历史上都没有一个创作工具，可以达到这种规模，毕竟全球网民也才50亿，你能想象每个月这世界上6个人中就有1个来剪视频不？这听起来就有点反常识。

假如剪映只是把剪视频的工具，比Premiere做的更简单易用，是不可能做这么大的。这里的关键方法论是低门槛工具->模板生态。具体说，通过一键式能力和素材降低门槛，让有创意的创作者做出优质的模板，沉淀在端内进行分发，然后普通用户套用模板后做出爆款，再引发更多跟风创意。另一个类似的产品是2亿月活的Canva。

之前在腾讯的时候，听张小龙分享，微信做产品是引入一个原子能力，然后在整个微信生态内引发化学反应，比如视频号不是单纯的上下滑feeds，而是嵌入到朋友圈、微信群、公众号、电商，当一个视频被流转，价值就不断增厚。如果视频号只是在微信里加个入口，那么其实流量也不大。再比如微信搜索接入deepseek，不是简单的AI搜索，而是把用户的私有数据和微信生态数据服务都通过大模型调动起来，聊天记录、公众号、视频号、问一问、小程序、小绿书、听一听，这里的想象空间非常大。

与微信类似，剪映做原子能力，也是会在端内的模板生态和更大的抖音生态，引发创意的乘数效应。有些功能的渗透不高，但可以做出非常酷炫的内容，内容爆款对产品的活跃和增长是极大的，可以带来增量的规模。

回到AI，过去产品做10个功能，就是10个按钮，所有人都是用这个10个按钮中的某几个。但AI产品，因为对话交互和模型的泛化能力，可能一天有100万个对话，归类下来，可能是1万个功能，如何把不同用户的最佳实践，沉淀在端内，供其他用户更低门槛的使用，甚至激发灵感，是AI产品值得尝试的方向。

### **22\. 模型首发就是流量，产品框架要最大化承接甚至放大模型进步的红利**

模型能力胜过产品雕花，应该是很多一线同学的超强共鸣。当模型能力迭代带来一个领先的新体验，给用户提供其他竞品没有的结果，只要找到合适的应用场景，就能快速爆发，远超产品雕花+运营拉花+推广撒币。数据涨得毫不费力，用户反馈超出预期，然后你就有了所谓第一性原理做事的爽感。这里的case，数不胜数，比如：

*   Remini首先把真人lora放在AI写真，成为23年最火的AI产品
    
*   Luma首先把sora的DiT视频模型做出来，通过AI拥抱瞬间火遍全球，超过Runway几年积累的用户规模
    
*   Pika首先把视频lora做成捏捏特效，逆风翻盘
    
*   即梦首发了中文字海报生成能力，用户规模和口碑暴涨
    
*   Deepseek做出首个开源和免费的推理模型，成为史上增长最快的AI产品
    
*   豆包上线seededit 3.0，让AI修图瞬间火爆全网
    

最近nano banana发布后，包括higgsfield在内的各几十个AI产品都光速接入了该模型，还限免。不禁感慨，当「模型首发就是红利」成为共识后，那么这个低垂的果实其实就已经没有了。去年经历过模型首发或接近首发的爆发式红利，真的很爽，躺赢的那种，今年越来越少了。

接下来更重要的是，**在模型都平权的情况下，你的产品，作为一个系统，如何因为增加一个模型，或者升级一个模型，让你的产品体验、用户心智比竞品更好**。这其实是更难的事情，并且需要在模型升级之前做好准备，没有那么多短平快的手段了。否则新模型哪怕很强，用户找不到入口，或者这个入口对应的场景预期跟模型能力不匹配，也白搭。

年初面对GPT 4O，我有绝望的感觉，我所做的那么多局部最优解的雕花，长期看可能都没价值，围绕局部最优解构建的所谓壁垒，都可能被模型巨人以意想不到的方式压碎，它不是正面冲击，而是漫不经心的轻轻横扫。但后面发现，这其实是好消息，产品不用花那么多资源去为模型打补丁，而是为模型发挥作用，设计更有价值的系统。

新发布一个强大的模型，假如价值是100分，有的产品框架适配，拿到100分，有的产品通过与其他能力和模型的组合搭配，可以拿到150分，有的产品框架限制了模型的发挥，拿到60分，有的完全没有模型发挥的地方，拿到0分，还有拿到负分，因为竞品会抢走用户。大家可以想一想，一个新模型的发布，你的产品可以拿走多少分。

### **23\. 复杂的工程链路最终会被模型简化，但一个基模吃不掉所有场景，所以应用层长期也会搞数据，训模型，做RL**

用户要结果，而不是过程。那处于末端的AI应用层的产品，如何来保证模型能交付好的结果呢？我们还是回到模型的本质是什么，是给它大量的数据集，然后它通过大量的学习训练，就学会了。

我们再来拆解，数据集都是什么，比如GPT是一段文本信息，让它在一定上下文窗口中基于前面的几个token猜下一个token，在ChatGPT阶段，给它喂对话的数据集，Q&A，然后它就学会了根据用户的提问来回答；比如Stable diffusion，数据集是一段文字描述+图片，这样它学会了根据prompt生成图片，再喂一批相似风格的图片，就可以训出粘土风lora，基于这个lora生成的图片都是粘土风；Sora的数据集则是一段文字描述+视频；

**这样你就会发现模型训练其实没有那么神秘，关键是定义你要的输入和输出结果，细化为测评标准，然后去收集、清洗、构造对应的数据集**，如果有又好又多的数据集，那么基于一个强大的开源模型，其实可以训出来你想要的模型能力的。

看似简单的道理，这几年也经历好多磨难和波折，吃了很多亏。在23年，ChatGPT 3.5没法用，所以自己训模型，但是发现业务数据看似多，实际很脏很复杂，清洗之后，符合要求的也不多，意识到业务数据不是壁垒。

24年，基模变得更强一些，于是围绕好的闭环和开源模型，做workflow、lora、SFT，为模型打了很多补丁，能做出一些小东西，但到了25年，都被一个强大的基模升级给覆盖了，发现之前的补丁也不再是壁垒了。

随着AI进入更多垂直行业，解决更复杂的场景需求，会发现一个基模能做很多事情，但做不好大部分事情。大家可能都听过那句 **Less structure, more intelligence，这句话是对的，但没有表面那么简单**。

如果你只是给Claude提供更多的context和tool，通过简单的架构来充分发挥模型的智力，那能做出通用agent，但其实还是集中在deep research、ppt之类的通用的文字工作任务。

**而这个世界上有太多复杂的高要求的任务，这些任务有很多的隐性知识和标准，对应的数据没有预训练到基模里。**如果你也是选一个基模+context+tool，你会发现你产品里给用户使用的tool，会限制模型的效果上限和范围。并且由于上下文窗口的限制，你只能选择有限数量的tool，以及对tool的工具描述要做到非常精准，否则很容易调用出幻觉。

怎么理解用户使用的tool会限制模型效果的上限？大家可以体验一下，即梦生图，如果想加文字，一种是选择传统字体，另一种是直接生成文字，无论样式还是跟画面的融合度，都是远超前者。虽然后者目前依然在小字上存在问题，但我们应该已经相信，生成文字的效果天花板更高。

做过Agent的同学，应该在被毒打过程中，会意识到，如果任务尽可能被模型本身完成，而不依赖过多的tool，那Agent的稳定性、上下文、场景泛化性，都会容易很多。不是一个模型，加上1万个人类的tool，就能做10万个事情的。

目前很多团队都在探索，**围绕各自的垂直场景，基于用户的input和output，去构造数据对pair，最终训练出一个垂类模型，尽可能以一个模型来解决该场景下的用户需求**。怎么做训练数据集，真是一门学问，也非常有意思，数据获取，不是单纯算法同学的事儿，因为他们擅长训模型，而不一定擅长找数据。经常需要产品、设计师的参与，大家一起想办法，有些数据构造方式真的是妙到拍大腿。

应用层的算法训练一般分两种，一种是SFT，就是准备高质量的数据，都是好答案，让模型照猫画猫，可以相对快速且容易的训出来，但SFT有过拟合的问题，简单说，就是如果实际场景是超出这些数据集的范围，比如照猫画虎，那么就画不出来老虎的气势，所以一般说来，SFT就要准备非常丰富多元的数据，来对冲过拟合的问题。

另一种是RL，也是今年的主流，准备好的、差的数据，通过一套标准reward model，如果模型回答得好，就给奖励，如果回答不好，就扣分，然后模型就学会怎么做出好的结果。RL更加符合人学习的本质规律，所以理论上表现会更好，泛化能力更强，不过训练难度大很多，一方面在很多开放式场景下，很难找到reward model，不是简单的rule based的围棋、编程和做数学题，另一方面模型训练过程中，也很容易训崩了，或者模型会作弊hack指标。

未来有两种方式，一种是一个基模，即一套权重parameter，拿到所有的context与现实世界交互，通过反馈机制，实现自我迭代，解决所有的问题，即AGI；另一个是不同的模型，每个模型都有各自的权重parameter，来应对各种复杂场景下的任务。目前看，短中期，后者更有可落地性。

### **24\. 核心逻辑要简单稳定，如果模型A 80% x 模型B 50% x 模型C 40%...最终结果就是10%**

满足用户的需求，可能不是单个模型就能解决，不然就直接在ChatGPT的聊天窗了。在应用层解决方案上，我们更多是**基于对用户需求场景的理解，可能需要调度组合多个模型。**

在前期验证需求阶段，可以快速搭建一个workflow，组合模型A和B，出来一个demo，来验证效果。到了后面，你会发现，每个模型都有幻觉、不可控的问题，以及模型跟模型之间的上下游协作，会存在信息丢失的情况，导致最终的结果就是 80%x50%x40%...=10%不可用，这也是为什么到今天Agent还没真正大范围跑通。

所以当我在看技术方案，如果核心链路非常绕、长、复杂，且每个环节都有不少bad case，就需要思考有没有其他的方式，或者把需求范围再收敛一下。不然通过大量的策略来兜底，会兜死过去。

理解和生成统一，实时生成，这些是基模的演进趋势，再结合业务场景下，通过RL进行端到端的模型训练，减少环节和信息折损，**未来模型能力足够强，模型数量足够收敛，就能通过更简单的交互、更短的耗时给用户提供更好的结果。**

好吧，其实24条跟23条讲的是一回事，但真的很重要，以及很多人还没有这块的共识，所以啰嗦一下。

### 25\. 把模型当做一个人，让模型干活之前，想一想人是怎么做的

这句话是今年对我做产品，最重要的一句话。经常在讨论方案时，大家各说各话，很难对齐思路时，我会问，这个任务，人是怎么做的？然后我们就很快能找到好的解决方案。当然，这里的人是指牛逼专业的人，不是菜鸡。如果让模型跟着菜鸡学，反倒是让模型比菜鸡还菜。

把模型当作一个人，聪明、自闭、记忆力短、关在笼子里，你来帮助它在你们业务landing，从而发挥它的才智，同时服务海量的用户。推荐看一部美剧《良医》，里面的自闭症天才医生墨菲，在同事们的信任和帮助下，逐渐成为患者信赖的医生，这里有很多磨合、了解的过程，但最重要的就是感受模型，理解业务，其他的技巧都是表面的。

也推荐看《记忆碎片》这部电影，因为模型的上下文窗口限制，它本质没有记忆力，跟男主一样，每天早上醒来，就要看一遍笔记本，才能知道自己是谁，要做什么，看完这部电影，你就知道为什么context engineering那么重要。

随着模型的多模态理解和生成统一，智力继续增强，耗时缩短，有眼睛、耳朵、嘴巴、手，模型会变得更像正常人，还会超越人。那它可以做更多人不擅长也不喜欢做的事情，甚至取代一些职业，打开职业目录，看看传统职业和新兴职业，可能这个 list 里存在不少垂直 agent 的机会。

我们所做的一切，都是为了让模型更像人，更聪明的、不知疲倦的、不受情绪困扰的人，这样的人，如果进入社会，工作起来，会非常高效、低成本，过去老板需要雇一个助理来处理杂事，后面每个人都有更强的助理。

生产力的变革，会带来生产关系的变化，那我们就要思考，身为人，我们的价值是什么，哪些是会被机器取代的，哪些是机器无法取代的。不是我煽动焦虑，而是身边已经有一些工作岗位，因为AI而变得比较危险了。

做AI产品会有失控的感觉，因为它不是死的工具，当硅基智力（AI）与碳基智力（用户）交互时，绝对会超出设计者（产品经理有限的脑子）的计划。不要对抗失控，学会接受和利用失控，我们要相信模型会进步，用户会变化，以及世界会变化。

思考本质，做关键的且有长期价值的事情，而不要疲于做缓解焦虑的事情，陷入恶性循环。

# 写在最后：

以上是我过去2年多的经验总结，可能有片面的地方，希望对大家有参考价值。

第一版发布于2月17日，原稿见https://docs.qq.com/doc/DTHdGdktBVFpnbkhI，从1.3w字增加1.9w字，有删减，有新增，有兴趣可以对照阅读，看看里面有多少判断是被打脸的。

也欢迎AI从业者加飞书群交流一线真知，目前已有字节、腾讯、阿里和AI创业公司的同学日常分享思考，行业变化太快，一个人闷头干很容易滞后。

![图片](assets/1763990379-37d80127b73f829661c0d17b431e0b18.svg)

  

![](assets/1763990379-613de3db1b1895678f52d7fc6e80adf9.jpg)

Kenny肯尼

[喜欢作者](javascript:)

作者提示: 个人观点，仅供参考
